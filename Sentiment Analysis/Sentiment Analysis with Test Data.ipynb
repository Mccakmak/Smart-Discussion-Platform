{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from functions import load_dataset\n",
    "from functions import remove_unwanted_cols\n",
    "from functions import preprocess_tweet_text\n",
    "from functions import get_feature_vector\n",
    "from functions import int_to_string\n",
    "from functions import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from wordcloud import WordCloud\n",
    "from pandas import option_context\n",
    "import ftplib\n",
    "import sched, time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>incredible india atulya bharat land seekers beproud plz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>near western union want make 300 today hit let walk process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>firstdayofschool students teachers good luck successful 2016 17 school year educationmatters ht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>kate wrights figure want life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>josh jenkins looking forward tab breeders crown super sunday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0    0.0   \n",
       "1    0.0   \n",
       "2    1.0   \n",
       "3    0.0   \n",
       "4    1.0   \n",
       "\n",
       "                                                                                              text  \n",
       "0                                          incredible india atulya bharat land seekers beproud plz  \n",
       "1                                      near western union want make 300 today hit let walk process  \n",
       "2  firstdayofschool students teachers good luck successful 2016 17 school year educationmatters ht  \n",
       "3                                                                    kate wrights figure want life  \n",
       "4                                     josh jenkins looking forward tab breeders crown super sunday  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 2357776 rows, 2 columns.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>821191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>460857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1067747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text\n",
       "label         \n",
       "-1.0    821191\n",
       " 0.0    460857\n",
       " 1.0   1067747"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load saved cleaned dataset\n",
    "dataset = load_dataset(\"cleaned_merge_dataset.csv\", [\"label\", \"text\"])\n",
    "display(dataset.groupby('label').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>458700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>460857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>459111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text\n",
       "label        \n",
       "-1.0   458700\n",
       " 0.0   460857\n",
       " 1.0   459111"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1382574"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Undersampling\n",
    "min_count_type = dataset.label.value_counts().min()\n",
    "sentiment_types = list(dataset.label.unique())\n",
    "subdatasets = list()\n",
    "for sentiment_type in sentiment_types :\n",
    "    dataset_sentiment_type = dataset[dataset['label']==sentiment_type]\n",
    "    dataset_sentiment_type = dataset_sentiment_type.sample(min_count_type)\n",
    "    subdatasets.append(dataset_sentiment_type)\n",
    "dataset_undersampled = pd.concat(subdatasets)\n",
    "dataset_undersampled.sample(frac=1)\n",
    "display(dataset_undersampled.groupby('label').count())\n",
    "\n",
    "dataset = pd.DataFrame(dataset_undersampled)\n",
    "display(dataset['text'].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF matrix, weighting factor\n",
    "tf_vector = get_feature_vector(np.array(dataset['text'].values.astype('U')).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>4.127788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>4.213376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>4.275816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>4.304319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>4.342580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>4.389845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>4.393865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>4.482952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got</th>\n",
       "      <td>4.574134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>4.609364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idf_weights\n",
       "new       4.127788\n",
       "day       4.213376\n",
       "get       4.275816\n",
       "good      4.304319\n",
       "today     4.342580\n",
       "love      4.389845\n",
       "like      4.393865\n",
       "go        4.482952\n",
       "got       4.574134\n",
       "one       4.609364"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>brothers</th>\n",
       "      <td>7.882456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liked</th>\n",
       "      <td>7.885280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lake</th>\n",
       "      <td>7.885280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asked</th>\n",
       "      <td>7.886696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blessed</th>\n",
       "      <td>7.888823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideas</th>\n",
       "      <td>7.888823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadly</th>\n",
       "      <td>7.889533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>china</th>\n",
       "      <td>7.889533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>university</th>\n",
       "      <td>7.889533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smartphone</th>\n",
       "      <td>7.890954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            idf_weights\n",
       "brothers       7.882456\n",
       "liked          7.885280\n",
       "lake           7.885280\n",
       "asked          7.886696\n",
       "blessed        7.888823\n",
       "ideas          7.888823\n",
       "sadly          7.889533\n",
       "china          7.889533\n",
       "university     7.889533\n",
       "smartphone     7.890954"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print idf values \n",
    "df_idf = pd.DataFrame(tf_vector.idf_, index=tf_vector.get_feature_names(),columns=[\"idf_weights\"]) \n",
    "\n",
    "# sort ascending \n",
    "display(df_idf.sort_values(by=['idf_weights'])[0:10])\n",
    "display(df_idf.sort_values(by=['idf_weights'])[1100:1110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360230</th>\n",
       "      <td>0.0</td>\n",
       "      <td>want work phoenix az view latest opening job f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177479</th>\n",
       "      <td>0.0</td>\n",
       "      <td>mars venus earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>0.0</td>\n",
       "      <td>brownies bomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292712</th>\n",
       "      <td>0.0</td>\n",
       "      <td>hassan aman twitter matte black acura nsx sigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289897</th>\n",
       "      <td>0.0</td>\n",
       "      <td>tips fit workout 10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                               text\n",
       "360230    0.0  want work phoenix az view latest opening job f...\n",
       "177479    0.0                                   mars venus earth\n",
       "1517      0.0                                      brownies bomb\n",
       "292712    0.0  hassan aman twitter matte black acura nsx sigh...\n",
       "289897    0.0                                tips fit workout 10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 393590)\t0.1863681359375416\n",
      "  (0, 384061)\t0.19900331896555\n",
      "  (0, 379734)\t0.2897220165307443\n",
      "  (0, 277425)\t0.3603957394762402\n",
      "  (0, 265908)\t0.3060627920051177\n",
      "  (0, 211656)\t0.2771011276578447\n",
      "  (0, 195604)\t0.3096159863978573\n",
      "  (0, 195550)\t0.25251155514008805\n",
      "  (0, 173437)\t0.3194483211949708\n",
      "  (0, 139949)\t0.3680785217261145\n",
      "  (0, 51439)\t0.379773644254873\n",
      "  (1, 378574)\t0.6593526711187568\n",
      "  (1, 229286)\t0.5635484053081756\n",
      "  (1, 122505)\t0.497661782703045\n",
      "  (2, 72819)\t0.7346835090847935\n",
      "  (2, 67713)\t0.6784100098604487\n",
      "  (3, 369269)\t0.14429355019600965\n",
      "  (3, 343273)\t0.3905157430614324\n",
      "  (3, 334575)\t0.37955512431920513\n",
      "  (3, 323937)\t0.31917618596919356\n",
      "  (3, 259727)\t0.3444326313043041\n",
      "  (3, 230570)\t0.24776775696211084\n",
      "  (3, 168371)\t0.32117948837991506\n",
      "  (3, 93709)\t0.26201568547421117\n",
      "  (3, 64429)\t0.15341459237008204\n",
      "  (3, 39291)\t0.33604845754389684\n",
      "  (3, 32145)\t0.3040485333770623\n",
      "  (4, 393760)\t0.5654985595861013\n",
      "  (4, 359277)\t0.5031343846352143\n",
      "  (4, 140940)\t0.5198797988063167\n",
      "  (4, 2285)\t0.39596990402919824\n"
     ]
    }
   ],
   "source": [
    "X = tf_vector.transform(np.array(dataset['text'].values.astype('U')).ravel())\n",
    "y = np.array(dataset.iloc[:, 0]).ravel()\n",
    "display(dataset.head(5))\n",
    "print(X[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into Train, Validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.01, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1368748, 403541)\n",
      "(13826, 403541)\n",
      "(1368748,)\n",
      "(13826,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes training accuracy: 0.8181337981863718%\n",
      "Naive Bayes test accuracy: 0.7850426732243599%\n",
      "LinearSVC training accuracy: 0.866339165427091%\n",
      "LinearSVC test accuracy: 0.8047880804281788%\n",
      "BernoulliNB training accuracy: 0.8127639273262866%\n",
      "BernoulliNB test accuracy: 0.7841024157384637%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mccak\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression training accuracy: 0.8149133368596703%\n",
      "Logistic Regression test accuracy: 0.8009547229856792%\n"
     ]
    }
   ],
   "source": [
    "# Training Naive Bayes model\n",
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train, y_train)\n",
    "print(\"Naive Bayes training accuracy: \" + str(NB_model.score(X_train, y_train)) + \"%\")\n",
    "print(\"Naive Bayes test accuracy: \" + str(NB_model.score(X_valid, y_valid)) + \"%\")\n",
    "\n",
    "# Training LinearSVC model\n",
    "LSVC_model = LinearSVC()\n",
    "LSVC_model.fit(X_train, y_train)\n",
    "print(\"LinearSVC training accuracy: \" + str(LSVC_model.score(X_train, y_train)) + \"%\")\n",
    "print(\"LinearSVC test accuracy: \" + str(LSVC_model.score(X_valid, y_valid)) + \"%\")\n",
    "\n",
    "# Saving LSVC model to later use\n",
    "#file = open('LSVC_model.pickle','wb')\n",
    "#pickle.dump(LSVC_model, file)\n",
    "#file.close()\n",
    "\n",
    "# Training Naive BernoulliNB model\n",
    "BNB_model = BernoulliNB()\n",
    "BNB_model.fit(X_train, y_train)\n",
    "print(\"BernoulliNB training accuracy: \" + str(BNB_model.score(X_train, y_train)) + \"%\")\n",
    "print(\"BernoulliNB test accuracy: \" + str(BNB_model.score(X_valid, y_valid)) + \"%\")\n",
    "\n",
    "# Training Logistics Regression model\n",
    "LR_model = LogisticRegression()\n",
    "LR_model.fit(X_train, y_train)\n",
    "print(\"Logistic Regression training accuracy: \" + str(LR_model.score(X_train, y_train)) + \"%\")\n",
    "print(\"Logistic Regression test accuracy: \" + str(LR_model.score(X_valid, y_valid)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment graph\n",
    "def draw_graph(df, topic):\n",
    "    \n",
    "    del df['topic_name']\n",
    "    \n",
    "    sentiments = df.groupby('sentiment').size()\n",
    "    \n",
    "    graph = df.groupby('sentiment').count().rename(columns={'comment_text': ''}).plot(\n",
    "    autopct= lambda p: '{:.1f}%({:.0f})'.format(p,(p/100)*sentiments.sum()),\n",
    "    startangle=90, \n",
    "    legend = False,\n",
    "    shadow=False,\n",
    "    figsize=(6, 6), \n",
    "    fontsize=11,\n",
    "    kind='pie', \n",
    "    colors = ['#c90e0e', '#b8b8b8', '#2dbd51'],\n",
    "    title=topic,\n",
    "    subplots=True)\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(\"outputs/\" + topic + \".png\")\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-19103bfdf97b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msend_sentiment_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\mccak\\appdata\\local\\programs\\python\\python38\\lib\\sched.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, blocking)\u001b[0m\n\u001b[0;32m    149\u001b[0m                 \u001b[0mdelayfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m                 \u001b[0maction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margument\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m                 \u001b[0mdelayfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# Let other threads run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-19103bfdf97b>\u001b[0m in \u001b[0;36msend_sentiment_result\u001b[1;34m(sc)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mdraw_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mftplib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFTP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ftp.smartdiscussionplatform.com'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'file@smartdiscussionplatform.com'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1YHDQ@i9XUl;'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"outputs/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtopic\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".png\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m                                       \u001b[1;31m# file to send\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorbinary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"STOR public_html/matrixes/sentiments/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtopic\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m# send the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mccak\\appdata\\local\\programs\\python\\python38\\lib\\ftplib.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, host, user, passwd, acct, timeout, source_address)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpasswd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macct\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mccak\\appdata\\local\\programs\\python\\python38\\lib\\ftplib.py\u001b[0m in \u001b[0;36mlogin\u001b[1;34m(self, user, passwd, acct)\u001b[0m\n\u001b[0;32m    408\u001b[0m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msendcmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'USER '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'3'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m             \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msendcmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PASS '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpasswd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'3'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msendcmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ACCT '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0macct\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mccak\\appdata\\local\\programs\\python\\python38\\lib\\ftplib.py\u001b[0m in \u001b[0;36msendcmd\u001b[1;34m(self, cmd)\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[1;34m'''Send a command and return the response.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputcmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvoidcmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mccak\\appdata\\local\\programs\\python\\python38\\lib\\ftplib.py\u001b[0m in \u001b[0;36mgetresp\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[1;31m# Raise various errors if the response indicates an error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetresp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetmultiline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebugging\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*resp*'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msanitize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mccak\\appdata\\local\\programs\\python\\python38\\lib\\ftplib.py\u001b[0m in \u001b[0;36mgetmultiline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;31m# these are separated by '\\n' characters in the string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetmultiline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'-'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mccak\\appdata\\local\\programs\\python\\python38\\lib\\ftplib.py\u001b[0m in \u001b[0;36mgetline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;31m# Raise EOFError if the connection is closed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxline\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxline\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"got more than %d bytes\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mccak\\appdata\\local\\programs\\python\\python38\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "s = sched.scheduler(time.time, time.sleep)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "def send_sentiment_result(sc): \n",
    "    \n",
    "    # Load not labeled test dataset\n",
    "\n",
    "    session = ftplib.FTP('ftp.smartdiscussionplatform.com','file@smartdiscussionplatform.com','1YHDQ@i9XUl;')\n",
    "    file = open('comments.csv','wb')                                             # name the file\n",
    "    session.retrbinary('RETR public_html/matrixes/comments.csv', file.write)     # read the file\n",
    "    file.close()                                                                        # close file and FTP\n",
    "    session.quit()\n",
    "    \n",
    "    # Read data\n",
    "    not_labeled_test_ds = pd.read_csv(\"comments.csv\")\n",
    "    original = not_labeled_test_ds\n",
    "    \n",
    "    # Remove column\n",
    "    column_list = [\"topic_name\",\"comment_text\"]\n",
    "    not_labeled_test_ds = not_labeled_test_ds[column_list]\n",
    "    \n",
    "    # Creating not labeled test data\n",
    "    not_labeled_test_ds.comment_text = not_labeled_test_ds[\"comment_text\"].apply(preprocess_tweet_text)\n",
    "    \n",
    "    # Features\n",
    "    not_labeled_test_feature = tf_vector.transform(np.array(not_labeled_test_ds.iloc[:, 1]).ravel())\n",
    "    \n",
    "    # Predict\n",
    "    test_prediction_lsvc = LSVC_model.predict(not_labeled_test_feature)\n",
    "\n",
    "    # Transform the integer labels to string labels\n",
    "    test_results = []\n",
    "    for test in test_prediction_lsvc:\n",
    "        test_results.append(int_to_string(test))\n",
    "    \n",
    "    # Append results to sentiment column\n",
    "    not_labeled_test_ds['sentiment'] = test_results\n",
    "    \n",
    "    # Get topic names\n",
    "    dfgroup = not_labeled_test_ds.groupby('topic_name')\n",
    "\n",
    "    topics = []\n",
    "\n",
    "    for topic,_ in dfgroup:\n",
    "        temp = re.sub(r'[^\\w\\s]','',topic)\n",
    "        topics.append(temp)\n",
    "        if temp != topic:\n",
    "            not_labeled_test_ds['topic_name'].loc[not_labeled_test_ds['topic_name'] == topic] = temp\n",
    "            \n",
    "    # Store the graphs on the server\n",
    "    for topic in topics:\n",
    "        \n",
    "        temp_df = not_labeled_test_ds.loc[not_labeled_test_ds['topic_name'] == topic]\n",
    "        draw_graph(temp_df, topic)\n",
    "    \n",
    "        session = ftplib.FTP('ftp.smartdiscussionplatform.com','file@smartdiscussionplatform.com','1YHDQ@i9XUl;')\n",
    "        file = open(\"outputs/\" + topic + \".png\",\"rb\")                                       # file to send\n",
    "        session.storbinary(\"STOR public_html/matrixes/sentiments/\" + topic + \".png\", file)     # send the file\n",
    "        file.close()                                                                 # close file and FTP\n",
    "        session.quit()\n",
    "    \n",
    "    \n",
    "    # Word Cloud\n",
    "\n",
    "    plt.ioff()\n",
    "\n",
    "    plt.figure(figsize = (20,20))\n",
    "    wc = WordCloud(max_words = 1000 , width = 1600 , height = 800,\n",
    "                   collocations=False).generate(\" \".join(list(not_labeled_test_ds['comment_text'])))\n",
    "\n",
    "    plt.imshow(wc)\n",
    "    plt.savefig(\"wordcloud.png\", format=\"PNG\", dpi=50, bbox_inches='tight')\n",
    "\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    session = ftplib.FTP('ftp.smartdiscussionplatform.com','file@smartdiscussionplatform.com','1YHDQ@i9XUl;')\n",
    "    file = open(\"wordcloud.png\",\"rb\")                                       # file to send\n",
    "    session.storbinary(\"STOR public_html/matrixes/wordclouds.png\", file)     # send the file\n",
    "    file.close()                                                                 # close file and FTP\n",
    "    session.quit()\n",
    "    \n",
    "    \n",
    "    s.enter(10, 1, send_sentiment_result, (sc,))\n",
    "\n",
    "s.enter(10, 1, send_sentiment_result, (s,))\n",
    "s.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
